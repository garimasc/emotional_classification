{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "819eaf45-dbe1-4e9a-9414-dbc429dbc191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = list(stopwords.words('english'))\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from pattern.en import lemma\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "62e6c363-a3cd-4ccb-bf36-c17f0e762f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i usually wear my hair in a twist out and when...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel so irritated and rejected by it or is g...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i can feel it disturbed within me</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im talking about down right i feel like slappi...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i almost feel like im messing with a precious ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label\n",
       "0  i usually wear my hair in a twist out and when...      joy\n",
       "1  i feel so irritated and rejected by it or is g...    anger\n",
       "2                  i can feel it disturbed within me  sadness\n",
       "3  im talking about down right i feel like slappi...    anger\n",
       "4  i almost feel like im messing with a precious ...      joy"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/dev_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdae8ea-bb8a-4388-9d91-56ca8b17e413",
   "metadata": {},
   "source": [
    "## Clean and Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "bc8f31dd-15d8-4861-9bdd-66f5bd8d851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text\n",
    "def clean_text(text):\n",
    "\n",
    "    # remove punctuation\n",
    "    reg_punc =re.compile(r'[^\\w\\s]')\n",
    "    text = reg_punc.sub(r'', text)\n",
    "\n",
    "    # remove html\n",
    "    reg_html = re.compile(r'<.*?>')\n",
    "    text = reg_html.sub(r'', text)\n",
    "\n",
    "    # remove url\n",
    "    reg_url = re.compile(r'http\\S+')\n",
    "    text = reg_url.sub(r'', text)\n",
    "\n",
    "    # remove numerical values\n",
    "    reg_num = re.compile(r'[0-9]')\n",
    "    text = reg_num.sub(r'', text)\n",
    "\n",
    "    # remove special characters\n",
    "    reg_spcl = re.compile('[@_!#$%^&*()<>?/\\\\|}{~:]')\n",
    "    text = reg_spcl.sub(r'', text)\n",
    "\n",
    "    # remove emoji\n",
    "    emoji_url = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_url.sub(r'', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Lemmatize text\n",
    "def lemmatize_text(text, remove_stopword= False, stop_words = [], lemmatizer= lemma):\n",
    "    if remove_stopword:\n",
    "        lemmatized_text = \" \".join([word if word.lower()==\"this\" else lemmatizer(word) for word in text.split() if word not in stop_words])\n",
    "    else:\n",
    "        lemmatized_text = \" \".join([word if word.lower()==\"this\" else lemmatizer(word) for word in text.split()])\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "60e35051-3fa7-4ab5-a8f2-78a0ba870041",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['process_text'] = data['text'].apply(lambda x: clean_text(x))\n",
    "data['process_text'] = data['process_text'].apply(lambda x: lemmatize_text(x, remove_stopword= True, stop_words= stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2b0ec259-e4f4-43ba-9dc0-ce9eddb93ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger', 'fear', 'joy', 'love', 'sadness', 'surprise']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions = data['label'].unique().tolist()\n",
    "emotions.sort()\n",
    "\n",
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5ad11d-bfa0-44a9-bca2-5b1f48d1bb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the top 10 really common words to stopwords list\n",
    "tmp_dict = WordCloud().process_text(\" \".join(data['process_text']))\n",
    "tmp_dict = sorted(tmp_dict.items(), key=lambda kv: kv[1])\n",
    "tmp_dict.reverse()\n",
    "tmp_dict = dict(tmp_dict)\n",
    "\n",
    "stop_words.extend([key for key,value in tmp_dict.items()][:30])\n",
    "stop_words.extend(['feel','think', 'like', 'would', 'really'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21155bce-2061-435e-8cef-81b1b7f43d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize= (14,6), ncols = 3, nrows= 2)\n",
    "\n",
    "wc_generator = WordCloud(width= 600, height= 400, background_color ='white', stopwords= stop_words)\n",
    "\n",
    "i = j = 0\n",
    "\n",
    "for ee in emotions:\n",
    "    # create dictionary of frequencies of words\n",
    "    tmp_data = data.query(f\"label == '{ee}'\")['process_text']\n",
    "    # remove any words that have a frequency of more than 5000\n",
    "    tmp_dict = wc_generator.process_text(\" \".join(tmp_data))\n",
    "    tmp_dict = {key:val for key, val in tmp_dict.items() if val < 5000 }\n",
    "    \n",
    "    wordcloud = wc_generator.generate_from_frequencies(tmp_dict)\n",
    "    axs[i,j].imshow(wordcloud)\n",
    "    axs[i,j].set_title(ee)\n",
    "    axs[i,j].get_yaxis().set_visible(False)\n",
    "    axs[i,j].get_xaxis().set_visible(False)\n",
    "\n",
    "    # increment column number\n",
    "    j += 1\n",
    "\n",
    "    # if more than 1 column, increase the row number\n",
    "    if j == 3:\n",
    "        i += 1\n",
    "        j = 0\n",
    "\n",
    "\n",
    "plt.tight_layout();\n",
    "fig.savefig(\"images/wordclouds.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9449ee-5bfd-45ae-b108-039ba62ce0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
