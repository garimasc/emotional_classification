{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "819eaf45-dbe1-4e9a-9414-dbc429dbc191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = list(stopwords.words('english'))\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\",\"parser\", \"ner\"])\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import recall_score, accuracy_score, classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.preprocess import clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdae8ea-bb8a-4388-9d91-56ca8b17e413",
   "metadata": {},
   "source": [
    "## Import pre-processed data\n",
    "\n",
    "Write a function to import pre-processed data for modelling. Currently, just reading from a previously saved csv file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1aebbab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger', 'fear', 'joy', 'love', 'sadness', 'surprise']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = pd.read_csv(\"data/dev_data.csv\")\n",
    "# data['process_text'] = data['text'].apply(lambda x: clean_text(x))\n",
    " \n",
    "# count = 0\n",
    "# for doc in nlp.pipe(data['process_text'].str.lower(), batch_size=32, n_process=3, disable=[\"tagger\",\"parser\", \"ner\"]):\n",
    "#     data.loc[count, \"process_text\"] = \" \".join([token.lemma_ for token in doc if token not in stop_words])\n",
    "#     count += 1\n",
    "\n",
    "data = pd.read_csv(\"data/lemmatized_dev_data.csv\")\n",
    "\n",
    "emotions = data['label'].unique().tolist()\n",
    "emotions.sort()\n",
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c5d2939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test dataset. Use only 100k samples to train and use the rest as test\n",
    "X_train,X_test, y_train, y_test = train_test_split(data['process_text'], data['label'], random_state=0,\n",
    "                                                   train_size= int(1e5), stratify= data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f01fb3d",
   "metadata": {},
   "source": [
    "### TF IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a397db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DenseTransformer since TF-IDF vectorization returns sparse matrices\n",
    "class DenseTransformer(TransformerMixin):\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.toarray()\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ace378",
   "metadata": {},
   "source": [
    "### Naive Bayes (Multinomial NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11a572d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy is: 0.86.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.93      0.80      0.86     32390\n",
      "        fear       0.88      0.75      0.81     27463\n",
      "         joy       0.81      0.97      0.88     78418\n",
      "        love       0.92      0.56      0.69     18992\n",
      "     sadness       0.88      0.94      0.91     67437\n",
      "    surprise       0.89      0.42      0.57      8233\n",
      "\n",
      "    accuracy                           0.86    232933\n",
      "   macro avg       0.88      0.74      0.79    232933\n",
      "weighted avg       0.87      0.86      0.85    232933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(min_df = 1e-3, max_df= 0.8, stop_words= stop_words, ngram_range= (1,2))),\n",
    "    ('dense', DenseTransformer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "nb_pipe.fit(X_train, y_train)\n",
    "y_pred = nb_pipe.predict(X_test)\n",
    "\n",
    "print(f\"Naive Bayes accuracy is: {accuracy_score(y_pred, y_test):0.2f}.\\n\")\n",
    "print(classification_report(y_test, y_pred, labels= emotions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a8b109",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9da6c47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class Logistic Regression accuracy is: 0.89.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.91      0.85      0.88     32390\n",
      "        fear       0.87      0.81      0.84     27463\n",
      "         joy       0.87      0.94      0.90     78418\n",
      "        love       0.83      0.76      0.79     18992\n",
      "     sadness       0.92      0.93      0.93     67437\n",
      "    surprise       0.80      0.73      0.76      8233\n",
      "\n",
      "    accuracy                           0.89    232933\n",
      "   macro avg       0.87      0.83      0.85    232933\n",
      "weighted avg       0.89      0.89      0.89    232933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(min_df = 1e-3, max_df= 0.8, stop_words= stop_words, ngram_range= (1,2))),\n",
    "    ('dense', DenseTransformer()),\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "])\n",
    "logreg_pipe.fit(X_train, y_train)\n",
    "y_pred = logreg_pipe.predict(X_test)\n",
    "\n",
    "print(f\"Multi-class Logistic Regression accuracy is: {accuracy_score(y_pred, y_test):0.2f}.\\n\")\n",
    "print(classification_report(y_test, y_pred, labels= emotions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "825dcdc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distracted</td>\n",
       "      <td>apprehensive</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>tender</td>\n",
       "      <td>dull</td>\n",
       "      <td>impressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dangerous</td>\n",
       "      <td>paranoid</td>\n",
       "      <td>resolved</td>\n",
       "      <td>sympathetic</td>\n",
       "      <td>jaded</td>\n",
       "      <td>shocked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rude</td>\n",
       "      <td>shaky</td>\n",
       "      <td>smug</td>\n",
       "      <td>horny</td>\n",
       "      <td>groggy</td>\n",
       "      <td>dazed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dissatisfied</td>\n",
       "      <td>hesitant</td>\n",
       "      <td>mellow</td>\n",
       "      <td>longing</td>\n",
       "      <td>aching</td>\n",
       "      <td>amazed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>envious</td>\n",
       "      <td>distressed</td>\n",
       "      <td>sincere</td>\n",
       "      <td>naughty</td>\n",
       "      <td>vain</td>\n",
       "      <td>curious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>greedy</td>\n",
       "      <td>shaken</td>\n",
       "      <td>clever</td>\n",
       "      <td>delicate</td>\n",
       "      <td>needy</td>\n",
       "      <td>stunned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bitchy</td>\n",
       "      <td>frantic</td>\n",
       "      <td>friendly</td>\n",
       "      <td>gentle</td>\n",
       "      <td>gloomy</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>irritable</td>\n",
       "      <td>fearful</td>\n",
       "      <td>pleasant</td>\n",
       "      <td>nostalgic</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bothered</td>\n",
       "      <td>intimidated</td>\n",
       "      <td>innocent</td>\n",
       "      <td>caring</td>\n",
       "      <td>unfortunate</td>\n",
       "      <td>overwhelmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>impatient</td>\n",
       "      <td>terrified</td>\n",
       "      <td>convinced</td>\n",
       "      <td>loyal</td>\n",
       "      <td>abused</td>\n",
       "      <td>strange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rushed</td>\n",
       "      <td>suspicious</td>\n",
       "      <td>intelligent</td>\n",
       "      <td>romantic</td>\n",
       "      <td>shitty</td>\n",
       "      <td>weird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>violent</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>trusting</td>\n",
       "      <td>supportive</td>\n",
       "      <td>deprived</td>\n",
       "      <td>amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fucked</td>\n",
       "      <td>reluctant</td>\n",
       "      <td>worthwhile</td>\n",
       "      <td>fond</td>\n",
       "      <td>messy</td>\n",
       "      <td>feel amazed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rebellious</td>\n",
       "      <td>skeptical</td>\n",
       "      <td>casual</td>\n",
       "      <td>hot</td>\n",
       "      <td>disheartened</td>\n",
       "      <td>feel impressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cranky</td>\n",
       "      <td>pressured</td>\n",
       "      <td>divine</td>\n",
       "      <td>devoted</td>\n",
       "      <td>rotten</td>\n",
       "      <td>feeling overwhelmed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           anger          fear          joy         love       sadness  \\\n",
       "0     distracted  apprehensive   acceptable       tender          dull   \n",
       "1      dangerous      paranoid     resolved  sympathetic         jaded   \n",
       "2           rude         shaky         smug        horny        groggy   \n",
       "3   dissatisfied      hesitant       mellow      longing        aching   \n",
       "4        envious    distressed      sincere      naughty          vain   \n",
       "5         greedy        shaken       clever     delicate         needy   \n",
       "6         bitchy       frantic     friendly       gentle        gloomy   \n",
       "7      irritable       fearful     pleasant    nostalgic   sentimental   \n",
       "8       bothered   intimidated     innocent       caring   unfortunate   \n",
       "9      impatient     terrified    convinced        loyal        abused   \n",
       "10        rushed    suspicious  intelligent     romantic        shitty   \n",
       "11       violent     uncertain     trusting   supportive      deprived   \n",
       "12        fucked     reluctant   worthwhile         fond         messy   \n",
       "13    rebellious     skeptical       casual          hot  disheartened   \n",
       "14        cranky     pressured       divine      devoted        rotten   \n",
       "\n",
       "               surprise  \n",
       "0             impressed  \n",
       "1               shocked  \n",
       "2                 dazed  \n",
       "3                amazed  \n",
       "4               curious  \n",
       "5               stunned  \n",
       "6             surprised  \n",
       "7                 funny  \n",
       "8           overwhelmed  \n",
       "9               strange  \n",
       "10                weird  \n",
       "11              amazing  \n",
       "12          feel amazed  \n",
       "13       feel impressed  \n",
       "14  feeling overwhelmed  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = logreg_pipe.named_steps['tfidf'].get_feature_names_out()\n",
    "\n",
    "n_max= 15\n",
    "res = pd.DataFrame(columns= emotions, index = range(0,n_max,1))\n",
    "\n",
    "for ii in range(0,len(emotions)):\n",
    "    res.loc[:,emotions[ii]] = pd.DataFrame(logreg_pipe.named_steps['clf'].estimators_[ii].coef_, columns= feature_names, \n",
    "                index= [emotions[ii]]).T.sort_values(emotions[ii], ascending= False).head(n_max).index\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a3a47723",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize= (15,7), ncols= 3, nrows= 2);\n",
    "plt.suptitle(\"Top 10 features for Logistic Regression One-vs-Rest Classifier\");\n",
    "\n",
    "tmp_x_train = logreg_pipe[:-1].transform(X_train.head(1000))\n",
    "\n",
    "ii = jj = 0;\n",
    "for ee in range(0,len(emotions)):\n",
    "\n",
    "    tmp_y_train = (y_train.head(1000) == emotions[ee]).astype(int)\n",
    "    # to get permutation: \n",
    "    results = permutation_importance(logreg_pipe[-1].estimators_[ee], tmp_x_train, tmp_y_train, scoring='recall',\n",
    "                                    n_repeats= 10, max_samples= 1000, n_jobs= 2, random_state= 0)\n",
    "\n",
    "    top_features = feature_names[np.argsort(results.importances_mean)][::-1][:10]\n",
    "    df_imp = pd.melt(pd.DataFrame(results.importances, index= feature_names).reindex(top_features).reset_index(), id_vars= \"index\")\n",
    "    df_imp.columns = ['feature','run','importance']\n",
    "\n",
    "\n",
    "    sns.boxplot(data= df_imp, x= \"feature\", y= \"importance\", order= top_features, color= \"coral\", ax= axs[ii,jj])\n",
    "    axs[ii,jj].tick_params(labelrotation= 30)\n",
    "    axs[ii,jj].set_yticks([])\n",
    "    axs[ii,jj].set_ylabel('')\n",
    "    axs[ii,jj].set_xlabel('')\n",
    "    axs[ii,jj].set_title(emotions[ee])\n",
    "\n",
    "    jj += 1\n",
    "    if jj > 2:\n",
    "        jj = 0\n",
    "        ii += 1\n",
    "    \n",
    "    del df_imp\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9cb435",
   "metadata": {},
   "source": [
    "### Support Vector \n",
    "We use the SGDClassifier implementation, which is fast and does not require Bagging.\n",
    "If we were to use SVC, the implementation scales quadratically with time, and in that case we would want to use BaggingClassfier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3c56836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class SVM accuracy is: 0.88.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.94      0.82      0.88     13889\n",
      "        fear       0.86      0.82      0.84     11776\n",
      "         joy       0.84      0.96      0.90     33625\n",
      "        love       0.88      0.69      0.77      8144\n",
      "     sadness       0.92      0.94      0.93     28916\n",
      "    surprise       0.91      0.63      0.74      3530\n",
      "\n",
      "    accuracy                           0.88     99880\n",
      "   macro avg       0.89      0.81      0.84     99880\n",
      "weighted avg       0.89      0.88      0.88     99880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(min_df = 1e-3, max_df= 0.6, stop_words= stop_words, ngram_range= (1,2))),\n",
    "    ('dense', DenseTransformer()),\n",
    "    ('clf', SGDClassifier(loss= 'hinge'))\n",
    "])\n",
    "svc_pipe.fit(X_train, y_train)\n",
    "y_pred = svc_pipe.predict(X_test)\n",
    "\n",
    "print(f\"Multi-class SVM accuracy is: {accuracy_score(y_pred, y_test):0.2f}.\\n\")\n",
    "print(classification_report(y_test, y_pred, labels= emotions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ee2abc",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3269fa79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class Logistic Regression accuracy is: 0.85.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.84      0.82      0.83     13889\n",
      "        fear       0.74      0.87      0.80     11776\n",
      "         joy       0.86      0.87      0.86     33625\n",
      "        love       0.78      0.75      0.76      8144\n",
      "     sadness       0.91      0.88      0.89     28916\n",
      "    surprise       0.87      0.62      0.72      3530\n",
      "\n",
      "    accuracy                           0.85     99880\n",
      "   macro avg       0.83      0.80      0.81     99880\n",
      "weighted avg       0.85      0.85      0.85     99880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(min_df = 1e-3, max_df= 0.6, stop_words= stop_words, ngram_range= (1,2))),\n",
    "    ('dense', DenseTransformer()),\n",
    "    ('clf', DecisionTreeClassifier(min_samples_split= 0.05))\n",
    "])\n",
    "tree_pipe.fit(X_train.head(50000), y_train.head(50000))\n",
    "y_pred = tree_pipe.predict(X_test)\n",
    "\n",
    "print(f\"Multi-class Logistic Regression accuracy is: {accuracy_score(y_pred, y_test):0.2f}.\\n\")\n",
    "print(classification_report(y_test, y_pred, labels= emotions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6bbe6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__max_samples': 5000, 'clf__min_samples_split': 50, 'clf__n_estimators': 100}\n",
      "Multi-class Random Forest accuracy is: 0.87.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.90      0.83      0.86     13889\n",
      "        fear       0.80      0.83      0.81     11776\n",
      "         joy       0.84      0.92      0.88     33625\n",
      "        love       0.83      0.71      0.77      8144\n",
      "     sadness       0.91      0.91      0.91     28916\n",
      "    surprise       0.88      0.63      0.73      3530\n",
      "\n",
      "    accuracy                           0.87     99880\n",
      "   macro avg       0.86      0.80      0.83     99880\n",
      "weighted avg       0.87      0.87      0.86     99880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(min_df = 1e-3, max_df= 0.6, stop_words= stop_words, ngram_range= (1,2))),\n",
    "    ('dense', DenseTransformer()),\n",
    "    ('clf', RandomForestClassifier(n_estimators= 10, max_samples= 5000, min_samples_split= 10))\n",
    "])\n",
    "# rf_pipe.fit(X_train, y_train)\n",
    "# y_pred = rf_pipe.predict(X_test)\n",
    "\n",
    "rf_grid= GridSearchCV(rf_pipe, param_grid= {'clf__n_estimators': [10,20,100],\n",
    "                                            'clf__max_samples':[5000],\n",
    "                                            'clf__min_samples_split': [10, 50, 100, 200, 500]}, scoring= 'accuracy', cv= 3)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "print(rf_grid.best_params_)\n",
    "y_pred = rf_grid.predict(X_test)\n",
    "\n",
    "print(f\"Multi-class Random Forest accuracy is: {accuracy_score(y_pred, y_test):0.2f}.\\n\")\n",
    "print(classification_report(y_test, y_pred, labels= emotions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee773ed",
   "metadata": {},
   "source": [
    "### Grid Search with Gradient Descent Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da6abf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV 1/3] END .................clf__alpha=0.0001;, score=0.881 total time=  16.7s\n",
      "[CV 2/3] END .................clf__alpha=0.0001;, score=0.883 total time=  22.7s\n",
      "[CV 3/3] END .................clf__alpha=0.0001;, score=0.882 total time=  19.4s\n",
      "[CV 1/3] END ..................clf__alpha=0.001;, score=0.870 total time=  19.3s\n",
      "[CV 2/3] END ..................clf__alpha=0.001;, score=0.871 total time=  35.2s\n",
      "[CV 3/3] END ..................clf__alpha=0.001;, score=0.871 total time=  35.8s\n",
      "[CV 1/3] END ...................clf__alpha=0.01;, score=0.868 total time=  16.3s\n",
      "[CV 2/3] END ...................clf__alpha=0.01;, score=0.871 total time=  18.6s\n",
      "[CV 3/3] END ...................clf__alpha=0.01;, score=0.871 total time=  18.2s\n",
      "[CV 1/3] END ....................clf__alpha=0.1;, score=0.869 total time=  17.3s\n",
      "[CV 2/3] END ....................clf__alpha=0.1;, score=0.871 total time=  17.5s\n",
      "[CV 3/3] END ....................clf__alpha=0.1;, score=0.868 total time=  17.5s\n",
      "[CV 1/3] END ......................clf__alpha=1;, score=0.849 total time=  17.4s\n",
      "[CV 2/3] END ......................clf__alpha=1;, score=0.850 total time=  17.6s\n",
      "[CV 3/3] END ......................clf__alpha=1;, score=0.846 total time=  17.4s\n",
      "{'clf__alpha': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "svc_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(min_df = 1e-3, max_df= 0.6, stop_words= stop_words, ngram_range= (1,2))),\n",
    "    ('dense', DenseTransformer()),\n",
    "    ('clf', SGDClassifier(loss= 'hinge', max_iter= 100, penalty= 'l2'))\n",
    "])\n",
    "svc_grid = GridSearchCV(svc_pipe, scoring= 'accuracy', cv=3, verbose= 3, \n",
    "                        param_grid= {'clf__alpha': [0.0001, 0.001, 0.01, 0.1, 1]})\n",
    "svc_grid.fit(X_train, y_train)\n",
    "print(svc_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "394166d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class SVM accuracy is: 0.88.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.93      0.83      0.88     13889\n",
      "        fear       0.87      0.81      0.83     11776\n",
      "         joy       0.85      0.96      0.90     33625\n",
      "        love       0.89      0.68      0.77      8144\n",
      "     sadness       0.91      0.94      0.93     28916\n",
      "    surprise       0.92      0.62      0.74      3530\n",
      "\n",
      "    accuracy                           0.88     99880\n",
      "   macro avg       0.89      0.81      0.84     99880\n",
      "weighted avg       0.89      0.88      0.88     99880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = svc_grid.predict(X_test)\n",
    "\n",
    "print(f\"Multi-class SVM accuracy is: {accuracy_score(y_pred, y_test):0.2f}.\\n\")\n",
    "print(classification_report(y_test, y_pred, labels= emotions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "536974d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV 1/3] END tfidf__max_df=0.5, tfidf__min_df=1e-05;, score=nan total time=   3.2s\n",
      "[CV 2/3] END tfidf__max_df=0.5, tfidf__min_df=1e-05;, score=nan total time=   3.3s\n",
      "[CV 3/3] END tfidf__max_df=0.5, tfidf__min_df=1e-05;, score=nan total time=   3.1s\n",
      "[CV 1/3] END tfidf__max_df=0.5, tfidf__min_df=0.0001;, score=0.867 total time= 1.5min\n",
      "[CV 2/3] END tfidf__max_df=0.5, tfidf__min_df=0.0001;, score=0.866 total time= 1.5min\n",
      "[CV 3/3] END tfidf__max_df=0.5, tfidf__min_df=0.0001;, score=0.870 total time= 1.4min\n",
      "[CV 1/3] END tfidf__max_df=0.5, tfidf__min_df=0.001;, score=0.860 total time=   7.7s\n",
      "[CV 2/3] END tfidf__max_df=0.5, tfidf__min_df=0.001;, score=0.861 total time=   7.2s\n",
      "[CV 3/3] END tfidf__max_df=0.5, tfidf__min_df=0.001;, score=0.862 total time=   7.1s\n",
      "[CV 1/3] END tfidf__max_df=0.5, tfidf__min_df=0.01;, score=0.359 total time=   5.2s\n",
      "[CV 2/3] END tfidf__max_df=0.5, tfidf__min_df=0.01;, score=0.359 total time=   5.1s\n",
      "[CV 3/3] END tfidf__max_df=0.5, tfidf__min_df=0.01;, score=0.362 total time=   5.2s\n",
      "[CV 1/3] END tfidf__max_df=0.6, tfidf__min_df=1e-05;, score=nan total time=   3.7s\n",
      "[CV 2/3] END tfidf__max_df=0.6, tfidf__min_df=1e-05;, score=nan total time=   3.6s\n",
      "[CV 3/3] END tfidf__max_df=0.6, tfidf__min_df=1e-05;, score=nan total time=   3.6s\n",
      "[CV 1/3] END tfidf__max_df=0.6, tfidf__min_df=0.0001;, score=0.867 total time= 1.7min\n",
      "[CV 2/3] END tfidf__max_df=0.6, tfidf__min_df=0.0001;, score=0.866 total time= 1.6min\n",
      "[CV 3/3] END tfidf__max_df=0.6, tfidf__min_df=0.0001;, score=0.870 total time= 1.6min\n",
      "[CV 1/3] END tfidf__max_df=0.6, tfidf__min_df=0.001;, score=0.860 total time=   7.6s\n",
      "[CV 2/3] END tfidf__max_df=0.6, tfidf__min_df=0.001;, score=0.861 total time=   7.4s\n",
      "[CV 3/3] END tfidf__max_df=0.6, tfidf__min_df=0.001;, score=0.862 total time=   7.2s\n",
      "[CV 1/3] END tfidf__max_df=0.6, tfidf__min_df=0.01;, score=0.359 total time=   5.8s\n",
      "[CV 2/3] END tfidf__max_df=0.6, tfidf__min_df=0.01;, score=0.359 total time=   5.1s\n",
      "[CV 3/3] END tfidf__max_df=0.6, tfidf__min_df=0.01;, score=0.362 total time=   5.2s\n",
      "[CV 1/3] END tfidf__max_df=0.75, tfidf__min_df=1e-05;, score=nan total time=   3.6s\n",
      "[CV 2/3] END tfidf__max_df=0.75, tfidf__min_df=1e-05;, score=nan total time=   3.8s\n",
      "[CV 3/3] END tfidf__max_df=0.75, tfidf__min_df=1e-05;, score=nan total time=   3.7s\n",
      "[CV 1/3] END tfidf__max_df=0.75, tfidf__min_df=0.0001;, score=0.867 total time= 2.3min\n",
      "[CV 2/3] END tfidf__max_df=0.75, tfidf__min_df=0.0001;, score=0.866 total time= 1.5min\n",
      "[CV 3/3] END tfidf__max_df=0.75, tfidf__min_df=0.0001;, score=0.870 total time= 1.6min\n",
      "[CV 1/3] END tfidf__max_df=0.75, tfidf__min_df=0.001;, score=0.860 total time=   7.8s\n",
      "[CV 2/3] END tfidf__max_df=0.75, tfidf__min_df=0.001;, score=0.861 total time=   6.9s\n",
      "[CV 3/3] END tfidf__max_df=0.75, tfidf__min_df=0.001;, score=0.862 total time=   7.5s\n",
      "[CV 1/3] END tfidf__max_df=0.75, tfidf__min_df=0.01;, score=0.359 total time=   5.5s\n",
      "[CV 2/3] END tfidf__max_df=0.75, tfidf__min_df=0.01;, score=0.361 total time=   5.9s\n",
      "[CV 3/3] END tfidf__max_df=0.75, tfidf__min_df=0.01;, score=0.362 total time=   5.5s\n",
      "[CV 1/3] END tfidf__max_df=0.8, tfidf__min_df=1e-05;, score=nan total time=   3.9s\n",
      "[CV 2/3] END tfidf__max_df=0.8, tfidf__min_df=1e-05;, score=nan total time=   4.1s\n",
      "[CV 3/3] END tfidf__max_df=0.8, tfidf__min_df=1e-05;, score=nan total time=   3.6s\n",
      "[CV 1/3] END tfidf__max_df=0.8, tfidf__min_df=0.0001;, score=0.867 total time= 1.6min\n",
      "[CV 2/3] END tfidf__max_df=0.8, tfidf__min_df=0.0001;, score=0.866 total time= 1.5min\n",
      "[CV 3/3] END tfidf__max_df=0.8, tfidf__min_df=0.0001;, score=0.870 total time= 1.5min\n",
      "[CV 1/3] END tfidf__max_df=0.8, tfidf__min_df=0.001;, score=0.860 total time=   7.6s\n",
      "[CV 2/3] END tfidf__max_df=0.8, tfidf__min_df=0.001;, score=0.861 total time=   7.2s\n",
      "[CV 3/3] END tfidf__max_df=0.8, tfidf__min_df=0.001;, score=0.862 total time=   7.0s\n",
      "[CV 1/3] END tfidf__max_df=0.8, tfidf__min_df=0.01;, score=0.359 total time=   5.8s\n",
      "[CV 2/3] END tfidf__max_df=0.8, tfidf__min_df=0.01;, score=0.361 total time=   5.1s\n",
      "[CV 3/3] END tfidf__max_df=0.8, tfidf__min_df=0.01;, score=0.362 total time=   5.0s\n",
      "[CV 1/3] END tfidf__max_df=0.85, tfidf__min_df=1e-05;, score=nan total time=   3.5s\n",
      "[CV 2/3] END tfidf__max_df=0.85, tfidf__min_df=1e-05;, score=nan total time=   3.5s\n",
      "[CV 3/3] END tfidf__max_df=0.85, tfidf__min_df=1e-05;, score=nan total time=   3.6s\n",
      "[CV 1/3] END tfidf__max_df=0.85, tfidf__min_df=0.0001;, score=0.867 total time= 1.5min\n",
      "[CV 2/3] END tfidf__max_df=0.85, tfidf__min_df=0.0001;, score=0.866 total time= 1.6min\n",
      "[CV 3/3] END tfidf__max_df=0.85, tfidf__min_df=0.0001;, score=0.870 total time= 1.7min\n",
      "[CV 1/3] END tfidf__max_df=0.85, tfidf__min_df=0.001;, score=0.860 total time= 8.7min\n",
      "[CV 2/3] END tfidf__max_df=0.85, tfidf__min_df=0.001;, score=0.861 total time=  11.4s\n",
      "[CV 3/3] END tfidf__max_df=0.85, tfidf__min_df=0.001;, score=0.862 total time=   8.3s\n",
      "[CV 1/3] END tfidf__max_df=0.85, tfidf__min_df=0.01;, score=0.359 total time=   6.4s\n",
      "[CV 2/3] END tfidf__max_df=0.85, tfidf__min_df=0.01;, score=0.361 total time=   5.9s\n",
      "[CV 3/3] END tfidf__max_df=0.85, tfidf__min_df=0.01;, score=0.362 total time=   6.1s\n",
      "[CV 1/3] END tfidf__max_df=0.9, tfidf__min_df=1e-05;, score=nan total time=   4.4s\n",
      "[CV 2/3] END tfidf__max_df=0.9, tfidf__min_df=1e-05;, score=nan total time=   4.4s\n",
      "[CV 3/3] END tfidf__max_df=0.9, tfidf__min_df=1e-05;, score=nan total time=   4.3s\n",
      "[CV 1/3] END tfidf__max_df=0.9, tfidf__min_df=0.0001;, score=0.867 total time= 1.6min\n",
      "[CV 2/3] END tfidf__max_df=0.9, tfidf__min_df=0.0001;, score=0.866 total time= 1.8min\n",
      "[CV 3/3] END tfidf__max_df=0.9, tfidf__min_df=0.0001;, score=0.870 total time= 1.5min\n",
      "[CV 1/3] END tfidf__max_df=0.9, tfidf__min_df=0.001;, score=0.860 total time=  10.1s\n",
      "[CV 2/3] END tfidf__max_df=0.9, tfidf__min_df=0.001;, score=0.861 total time=   8.9s\n",
      "[CV 3/3] END tfidf__max_df=0.9, tfidf__min_df=0.001;, score=0.862 total time=   8.4s\n",
      "[CV 1/3] END tfidf__max_df=0.9, tfidf__min_df=0.01;, score=0.359 total time=   6.1s\n",
      "[CV 2/3] END tfidf__max_df=0.9, tfidf__min_df=0.01;, score=0.361 total time=   6.1s\n",
      "[CV 3/3] END tfidf__max_df=0.9, tfidf__min_df=0.01;, score=0.362 total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "18 fits failed out of a total of 72.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_17748\\689574492.py\", line 8, in fit_transform\n",
      "    return self.transform(X)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_17748\\689574492.py\", line 4, in transform\n",
      "    return X.toarray()\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\scipy\\sparse\\_compressed.py\", line 1106, in toarray\n",
      "    out = self._process_toarray_args(order, out)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\scipy\\sparse\\_base.py\", line 1327, in _process_toarray_args\n",
      "    return np.zeros(self.shape, dtype=self.dtype, order=order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 182. GiB for an array with shape (155368, 157593) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_17748\\689574492.py\", line 8, in fit_transform\n",
      "    return self.transform(X)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_17748\\689574492.py\", line 4, in transform\n",
      "    return X.toarray()\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\scipy\\sparse\\_compressed.py\", line 1106, in toarray\n",
      "    out = self._process_toarray_args(order, out)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\scipy\\sparse\\_base.py\", line 1327, in _process_toarray_args\n",
      "    return np.zeros(self.shape, dtype=self.dtype, order=order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 182. GiB for an array with shape (155369, 157505) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_17748\\689574492.py\", line 8, in fit_transform\n",
      "    return self.transform(X)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_17748\\689574492.py\", line 4, in transform\n",
      "    return X.toarray()\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\scipy\\sparse\\_compressed.py\", line 1106, in toarray\n",
      "    out = self._process_toarray_args(order, out)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\scipy\\sparse\\_base.py\", line 1327, in _process_toarray_args\n",
      "    return np.zeros(self.shape, dtype=self.dtype, order=order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 182. GiB for an array with shape (155369, 157490) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_17748\\689574492.py\", line 8, in fit_transform\n",
      "    return self.transform(X)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_17748\\689574492.py\", line 4, in transform\n",
      "    return X.toarray()\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\scipy\\sparse\\_compressed.py\", line 1106, in toarray\n",
      "    out = self._process_toarray_args(order, out)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\scipy\\sparse\\_base.py\", line 1327, in _process_toarray_args\n",
      "    return np.zeros(self.shape, dtype=self.dtype, order=order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 182. GiB for an array with shape (155368, 157594) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_17748\\689574492.py\", line 8, in fit_transform\n",
      "    return self.transform(X)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_17748\\689574492.py\", line 4, in transform\n",
      "    return X.toarray()\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\scipy\\sparse\\_compressed.py\", line 1106, in toarray\n",
      "    out = self._process_toarray_args(order, out)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\scipy\\sparse\\_base.py\", line 1327, in _process_toarray_args\n",
      "    return np.zeros(self.shape, dtype=self.dtype, order=order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 182. GiB for an array with shape (155369, 157506) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_17748\\689574492.py\", line 8, in fit_transform\n",
      "    return self.transform(X)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_17748\\689574492.py\", line 4, in transform\n",
      "    return X.toarray()\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\scipy\\sparse\\_compressed.py\", line 1106, in toarray\n",
      "    out = self._process_toarray_args(order, out)\n",
      "  File \"c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\scipy\\sparse\\_base.py\", line 1327, in _process_toarray_args\n",
      "    return np.zeros(self.shape, dtype=self.dtype, order=order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 182. GiB for an array with shape (155369, 157491) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan 0.86784981 0.86082136 0.36014126        nan 0.86784981\n",
      " 0.86082136 0.36014126        nan 0.86784122 0.86077416 0.36045879\n",
      "        nan 0.86784122 0.86077416 0.36045879        nan 0.86784122\n",
      " 0.86077416 0.36045879        nan 0.86784122 0.86077416 0.36045879]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy is: 0.87.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.94      0.83      0.88     13889\n",
      "        fear       0.88      0.78      0.83     11776\n",
      "         joy       0.83      0.97      0.90     33625\n",
      "        love       0.91      0.57      0.70      8144\n",
      "     sadness       0.89      0.96      0.92     28916\n",
      "    surprise       0.91      0.42      0.58      3530\n",
      "\n",
      "    accuracy                           0.87     99880\n",
      "   macro avg       0.90      0.76      0.80     99880\n",
      "weighted avg       0.88      0.87      0.87     99880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(min_df = 1e-3, max_df= 0.6, stop_words= stop_words, ngram_range= (1,2))),\n",
    "    ('dense', DenseTransformer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "nb_grid = GridSearchCV(nb_pipe, scoring= 'accuracy', cv= 3, verbose= 3, \n",
    "                       param_grid= {'tfidf__max_df': [0.5, 0.6, 0.75, 0.8, 0.85, 0.9],\n",
    "                                    'tfidf__min_df': [1e-5, 1e-4, 1e-3, 1e-2]})\n",
    "nb_grid.fit(X_train, y_train)\n",
    "y_pred = nb_grid.predict(X_test)\n",
    "\n",
    "print(f\"Naive Bayes accuracy is: {accuracy_score(y_pred, y_test):0.2f}.\\n\")\n",
    "print(classification_report(y_test, y_pred, labels= emotions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acf0f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
