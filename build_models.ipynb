{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "819eaf45-dbe1-4e9a-9414-dbc429dbc191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = list(stopwords.words('english'))\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\",\"parser\", \"ner\"])\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import recall_score, accuracy_score, classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdae8ea-bb8a-4388-9d91-56ca8b17e413",
   "metadata": {},
   "source": [
    "## Import pre-processed data\n",
    "\n",
    "Write a function to import pre-processed data for modelling. Currently, just reading from a previously saved csv file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60e35051-3fa7-4ab5-a8f2-78a0ba870041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger', 'fear', 'joy', 'love', 'sadness', 'surprise']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/lemmatized_dev_data.csv\")\n",
    "\n",
    "emotions = data['label'].unique().tolist()\n",
    "emotions.sort()\n",
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c5d2939",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(data['process_text'], data['label'], random_state=0,\n",
    "                                                   test_size= 0.3, stratify= data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f01fb3d",
   "metadata": {},
   "source": [
    "### TF IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a397db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DenseTransformer since TF-IDF vectorization returns sparse matrices\n",
    "class DenseTransformer(TransformerMixin):\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.toarray()\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ace378",
   "metadata": {},
   "source": [
    "### Naive Bayes (Multinomial NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11a572d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy is: 0.86.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.94      0.81      0.87     13889\n",
      "        fear       0.88      0.75      0.81     11776\n",
      "         joy       0.82      0.96      0.88     33625\n",
      "        love       0.91      0.57      0.70      8144\n",
      "     sadness       0.88      0.95      0.91     28916\n",
      "    surprise       0.88      0.46      0.61      3530\n",
      "\n",
      "    accuracy                           0.86     99880\n",
      "   macro avg       0.88      0.75      0.80     99880\n",
      "weighted avg       0.87      0.86      0.86     99880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(min_df = 1e-3, max_df= 0.6, stop_words= stop_words, ngram_range= (1,2))),\n",
    "    ('dense', DenseTransformer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "nb_pipe.fit(X_train, y_train)\n",
    "y_pred = nb_pipe.predict(X_test)\n",
    "\n",
    "print(f\"Naive Bayes accuracy is: {accuracy_score(y_pred, y_test):0.2f}.\\n\")\n",
    "print(classification_report(y_test, y_pred, labels= emotions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a8b109",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9da6c47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class Logistic Regression accuracy is: 0.89.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.91      0.86      0.88     13889\n",
      "        fear       0.86      0.80      0.83     11776\n",
      "         joy       0.87      0.94      0.90     33625\n",
      "        love       0.82      0.77      0.80      8144\n",
      "     sadness       0.93      0.93      0.93     28916\n",
      "    surprise       0.79      0.73      0.76      3530\n",
      "\n",
      "    accuracy                           0.89     99880\n",
      "   macro avg       0.87      0.84      0.85     99880\n",
      "weighted avg       0.89      0.89      0.89     99880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(min_df = 1e-3, max_df= 0.6, stop_words= stop_words, ngram_range= (1,2))),\n",
    "    ('dense', DenseTransformer()),\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "])\n",
    "logreg_pipe.fit(X_train, y_train)\n",
    "y_pred = logreg_pipe.predict(X_test)\n",
    "\n",
    "print(f\"Multi-class Logistic Regression accuracy is: {accuracy_score(y_pred, y_test):0.2f}.\\n\")\n",
    "print(classification_report(y_test, y_pred, labels= emotions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "825dcdc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dissatisfied</td>\n",
       "      <td>apprehensive</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>tender</td>\n",
       "      <td>groggy</td>\n",
       "      <td>dazed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>greedy</td>\n",
       "      <td>shaken</td>\n",
       "      <td>resolved</td>\n",
       "      <td>sympathetic</td>\n",
       "      <td>disheartened</td>\n",
       "      <td>shocked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dangerous</td>\n",
       "      <td>frantic</td>\n",
       "      <td>mellow</td>\n",
       "      <td>horny</td>\n",
       "      <td>needy</td>\n",
       "      <td>stunned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>envious</td>\n",
       "      <td>hesitant</td>\n",
       "      <td>sincere</td>\n",
       "      <td>delicate</td>\n",
       "      <td>abused</td>\n",
       "      <td>impressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>irritable</td>\n",
       "      <td>pressured</td>\n",
       "      <td>smug</td>\n",
       "      <td>naughty</td>\n",
       "      <td>discontent</td>\n",
       "      <td>amazed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>distracted</td>\n",
       "      <td>distressed</td>\n",
       "      <td>triumphant</td>\n",
       "      <td>longing</td>\n",
       "      <td>jaded</td>\n",
       "      <td>curious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rebellious</td>\n",
       "      <td>reluctant</td>\n",
       "      <td>trusting</td>\n",
       "      <td>loyal</td>\n",
       "      <td>vain</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>petty</td>\n",
       "      <td>fearful</td>\n",
       "      <td>casual</td>\n",
       "      <td>gentle</td>\n",
       "      <td>gloomy</td>\n",
       "      <td>funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bothered</td>\n",
       "      <td>intimidated</td>\n",
       "      <td>virtuous</td>\n",
       "      <td>devoted</td>\n",
       "      <td>homesick</td>\n",
       "      <td>overwhelmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bitchy</td>\n",
       "      <td>shaky</td>\n",
       "      <td>intelligent</td>\n",
       "      <td>caring</td>\n",
       "      <td>rotten</td>\n",
       "      <td>amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fucked</td>\n",
       "      <td>suspicious</td>\n",
       "      <td>clever</td>\n",
       "      <td>romantic</td>\n",
       "      <td>melancholy</td>\n",
       "      <td>strange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rushed</td>\n",
       "      <td>uptight</td>\n",
       "      <td>innocent</td>\n",
       "      <td>fond</td>\n",
       "      <td>doomed</td>\n",
       "      <td>weird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rude</td>\n",
       "      <td>skeptical</td>\n",
       "      <td>pleasant</td>\n",
       "      <td>compassionate</td>\n",
       "      <td>dull</td>\n",
       "      <td>feel funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bitter</td>\n",
       "      <td>paranoid</td>\n",
       "      <td>convinced</td>\n",
       "      <td>supportive</td>\n",
       "      <td>aching</td>\n",
       "      <td>feel amazed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>violent</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>carefree</td>\n",
       "      <td>nostalgic</td>\n",
       "      <td>unfortunate</td>\n",
       "      <td>feel impressed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           anger          fear          joy           love       sadness  \\\n",
       "0   dissatisfied  apprehensive   acceptable         tender        groggy   \n",
       "1         greedy        shaken     resolved    sympathetic  disheartened   \n",
       "2      dangerous       frantic       mellow          horny         needy   \n",
       "3        envious      hesitant      sincere       delicate        abused   \n",
       "4      irritable     pressured         smug        naughty    discontent   \n",
       "5     distracted    distressed   triumphant        longing         jaded   \n",
       "6     rebellious     reluctant     trusting          loyal          vain   \n",
       "7          petty       fearful       casual         gentle        gloomy   \n",
       "8       bothered   intimidated     virtuous        devoted      homesick   \n",
       "9         bitchy         shaky  intelligent         caring        rotten   \n",
       "10        fucked    suspicious       clever       romantic    melancholy   \n",
       "11        rushed       uptight     innocent           fond        doomed   \n",
       "12          rude     skeptical     pleasant  compassionate          dull   \n",
       "13        bitter      paranoid    convinced     supportive        aching   \n",
       "14       violent     uncertain     carefree      nostalgic   unfortunate   \n",
       "\n",
       "          surprise  \n",
       "0            dazed  \n",
       "1          shocked  \n",
       "2          stunned  \n",
       "3        impressed  \n",
       "4           amazed  \n",
       "5          curious  \n",
       "6        surprised  \n",
       "7            funny  \n",
       "8      overwhelmed  \n",
       "9          amazing  \n",
       "10         strange  \n",
       "11           weird  \n",
       "12      feel funny  \n",
       "13     feel amazed  \n",
       "14  feel impressed  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = logreg_pipe.named_steps['tfidf'].get_feature_names_out()\n",
    "\n",
    "n_max= 15\n",
    "res = pd.DataFrame(columns= emotions, index = range(0,n_max,1))\n",
    "\n",
    "for ii in range(0,len(emotions)):\n",
    "    res.loc[:,emotions[ii]] = pd.DataFrame(logreg_pipe.named_steps['clf'].estimators_[ii].coef_, columns= feature_names, \n",
    "                index= [emotions[ii]]).T.sort_values(emotions[ii], ascending= False).head(n_max).index\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9c37a19",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m tmp_x_train \u001b[38;5;241m=\u001b[39m logreg_pipe[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtransform(X_train)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# to get permutation: \u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpermutation_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogreg_pipe\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_x_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\inspection\\_permutation_importance.py:267\u001b[0m, in \u001b[0;36mpermutation_importance\u001b[1;34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state, sample_weight, max_samples)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Permutation importance for feature evaluation [BRE]_.\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \n\u001b[0;32m    150\u001b[0m \u001b[38;5;124;03mThe :term:`estimator` is required to be a fitted estimator. `X` can be the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03marray([0.2211..., 0.       , 0.       ])\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 267\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# Precompute random seed from the random state to be used\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;66;03m# to get a fresh independent RandomState instance for each\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;66;03m# parallel call to _calculate_permutation_scores, irrespective of\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;66;03m# the fact that variables are shared or not depending on the active\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;66;03m# joblib backend (sequential, thread-based or process-based).\u001b[39;00m\n\u001b[0;32m    274\u001b[0m random_state \u001b[38;5;241m=\u001b[39m check_random_state(random_state)\n",
      "File \u001b[1;32mc:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\utils\\validation.py:1049\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1043\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1045\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1046\u001b[0m     )\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1049\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1058\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\sklearn\\utils\\validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# everything is finite; fall back to O(n) space `np.isinf/isnan` or custom\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# Cython implementation to prevent false positives and provide a detailed\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# error message.\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(over\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 122\u001b[0m     first_pass_isfinite \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39misfinite(\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2310\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   2311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[1;32m-> 2313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2314\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\garim\\anaconda3\\envs\\github\\lib\\site-packages\\numpy\\core\\fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tmp_x_train = logreg_pipe[:-1].transform(X_train)\n",
    "# to get permutation: \n",
    "results = permutation_importance(logreg_pipe[-1], tmp_x_train, y_train, scoring='accuracy',\n",
    "                                 n_repeats= 1)\n",
    "# # get important features:\n",
    "# important_features = results.importances_mean\n",
    "# # list all features:\n",
    "# # for i,v in enumerate(important_features):\n",
    "# #     print('Feature: %0d, Score: %.5f' % (i,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a47723",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
